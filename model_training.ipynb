{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3710jvsc74a57bd093f4f5b237b8f8df832884c2e2dec106b12a1aa580993933cf7074bb792b7374",
   "display_name": "Python 3.7.10 64-bit ('chessenv': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "93f4f5b237b8f8df832884c2e2dec106b12a1aa580993933cf7074bb792b7374"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "exec time: 4.9591s\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import torch\n",
    "\n",
    "start = time.time()\n",
    "df = pd.read_csv('cleaned_puzzle_batches/cleaned_train_batch_1.csv')\n",
    "\n",
    "output_df = df.filter(like='theme')\n",
    "input_cols = [col_name for col_name in df.columns if not col_name.startswith('theme')]\n",
    "input_df = df.filter(items=input_cols)\n",
    "\n",
    "corr_df = output_df.apply(lambda x: input_df.corrwith(x))\n",
    "\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "duration = end - start\n",
    "print(\"exec time: %.4fs\" % duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/bastosgabriel/miniconda3/envs/chessenv/lib/python3.7/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at  /opt/conda/conda-bld/pytorch_1616554800319/work/c10/cuda/CUDAFunctions.cpp:109.)\n  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessData(torch.utils.data.Dataset):\n",
    "    def __init__(self, path):\n",
    "        self.df = pd.read_csv(path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = df.iloc[idx]\n",
    "\n",
    "        inputs = row[:321].values\n",
    "        outputs = row[321:].values\n",
    "\n",
    "        return {'board': inputs, 'themes': outputs}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7fc364836410>\nbatch['board']: tensor([[ 0.,  0.,  0.,  ..., -1.,  0.,  1.],\n        [ 0.,  0.,  0.,  ...,  0.,  0.,  1.],\n        [ 0.,  0.,  0.,  ...,  0.,  0., -1.],\n        ...,\n        [ 0.,  0.,  0.,  ...,  0.,  0.,  1.],\n        [ 0.,  0.,  0.,  ...,  0.,  0., -1.],\n        [ 0.,  0.,  0.,  ..., -1.,  0., -1.]], dtype=torch.float64)\nbatch['themes']: tensor([[0., 1., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 1., 0.,  ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 1., 0.,  ..., 0., 0., 0.],\n        [0., 1., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\nbatch['themes']: torch.Size([64, 27])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "chess_data_set = ChessData('cleaned_puzzle_batches/cleaned_train_batch_1.csv')\n",
    "\n",
    "train_dataloader = DataLoader(chess_data_set, batch_size=64, shuffle=True)\n",
    "print(train_dataloader)\n",
    "\n",
    "# Display image and label.\n",
    "batch = next(iter(train_dataloader))\n",
    "print(f\"batch['board']: {batch['board']}\")\n",
    "print(f\"batch['themes']: {batch['themes']}\")\n",
    "print(f\"batch['themes']: {batch['themes'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "net = nn.Sequential(nn.Linear(321, 27))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "\n",
    "loss = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-084a1359c376>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'board'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/chessenv/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    X = batch['board'].cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}